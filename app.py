# -*- coding: utf-8 -*-
"""
AIOps Agent - Main Application (Improved v2)
=============================================
æ”¹å–„ç‚¹:
1. ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒã‚¿ãƒ¼çµ±åˆ
2. ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œ
3. infer_root_cause (ãƒãƒƒãƒå‡¦ç†å¯¾å¿œ) ã®åˆ©ç”¨
4. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–
"""

import streamlit as st
import graphviz
import os
import time
import google.generativeai as genai
import json
import re
import pandas as pd
from google.api_core import exceptions as google_exceptions

# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç¾¤ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from data import TOPOLOGY
from logic import CausalInferenceEngine, Alarm, simulate_cascade_failure
from network_ops import (
    run_diagnostic_simulation,
    generate_remediation_commands,
    generate_analyst_report,
    generate_analyst_report_streaming,
    generate_remediation_commands_streaming,
    compute_cache_hash,
    predict_initial_symptoms,
    generate_fake_log_by_ai,
    run_remediation_parallel_v2,
    RemediationEnvironment,
    RemediationResult
)
from verifier import verify_log_content, format_verification_report
from inference_engine import LogicalRCA
from rate_limiter import GlobalRateLimiter, RateLimitConfig

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="Antigravity Autonomous", page_icon="âš¡", layout="wide")

# =====================================================
# ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒã‚¿ãƒ¼åˆæœŸåŒ–
# =====================================================
@st.cache_resource
def get_rate_limiter():
    """ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒã‚¿ãƒ¼ã®ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—"""
    return GlobalRateLimiter(RateLimitConfig(
        rpm=30,
        rpd=14400,
        safety_margin=0.8
    ))

rate_limiter = get_rate_limiter()

# =====================================================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# =====================================================
def find_target_node_id(topology, node_type=None, layer=None, keyword=None):
    """ãƒˆãƒãƒ­ã‚¸ãƒ¼ã‹ã‚‰æ¡ä»¶ã«åˆã†ãƒãƒ¼ãƒ‰IDã‚’æ¤œç´¢"""
    for node_id, node in topology.items():
        if node_type and node.type != node_type:
            continue
        if layer and node.layer != layer:
            continue
        if keyword:
            hit = False
            if keyword in node_id:
                hit = True
            for v in node.metadata.values():
                if isinstance(v, str) and keyword in v:
                    hit = True
            if not hit:
                continue
        return node_id
    return None


def load_config_by_id(device_id):
    """configsãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    possible_paths = [f"configs/{device_id}.txt", f"{device_id}.txt"]
    for path in possible_paths:
        if os.path.exists(path):
            try:
                with open(path, "r", encoding="utf-8") as f:
                    return f.read()
            except Exception:
                pass
    return "Config file not found."


def generate_content_with_retry(model, prompt, stream=True, retries=3):
    """503ã‚¨ãƒ©ãƒ¼å¯¾ç­–ã®ãƒªãƒˆãƒ©ã‚¤ä»˜ãç”Ÿæˆé–¢æ•°ï¼ˆãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒã‚¿ãƒ¼çµ±åˆï¼‰"""
    for i in range(retries):
        try:
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¾…æ©Ÿ
            if not rate_limiter.wait_for_slot(timeout=60):
                raise RuntimeError("Rate limit timeout")
            rate_limiter.record_request()
            return model.generate_content(prompt, stream=stream)
        except google_exceptions.ServiceUnavailable:
            if i == retries - 1:
                raise
            time.sleep(2 * (i + 1))
        except Exception as e:
            if '429' in str(e) or 'rate' in str(e).lower():
                if i == retries - 1:
                    raise
                time.sleep(5 * (i + 1))
            else:
                raise
    return None


def _pick_first(mapping: dict, keys: list, default: str = "") -> str:
    """Return the first non-empty value for the given keys from mapping"""
    for k in keys:
        try:
            v = mapping.get(k, None)
        except Exception:
            v = None
        if v is None:
            continue
        if isinstance(v, (int, float, bool)):
            s = str(v)
            if s:
                return s
        elif isinstance(v, str):
            if v.strip():
                return v.strip()
        else:
            try:
                s = json.dumps(v, ensure_ascii=False)
                if s and s != "null":
                    return s
            except Exception:
                continue
    return default


def _build_ci_context_for_chat(target_node_id: str) -> dict:
    """ãƒãƒ£ãƒƒãƒˆç”¨ã®CIã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰"""
    node = TOPOLOGY.get(target_node_id) if target_node_id else None
    md = (getattr(node, "metadata", None) or {}) if node else {}

    ci = {
        "device_id": target_node_id or "",
        "hostname": _pick_first(md, ["hostname", "host", "name"], default=(target_node_id or "")),
        "vendor": _pick_first(md, ["vendor", "manufacturer", "maker", "brand"], default=""),
        "os": _pick_first(md, ["os", "platform", "os_name", "software", "sw"], default=""),
        "model": _pick_first(md, ["model", "hw_model", "product", "sku"], default=""),
        "role": _pick_first(md, ["role", "type", "device_role"], default=""),
        "layer": _pick_first(md, ["layer", "level", "network_layer"], default=""),
        "site": _pick_first(md, ["site", "dc", "datacenter", "location"], default=""),
        "tenant": _pick_first(md, ["tenant", "customer", "org", "company"], default=""),
        "mgmt_ip": _pick_first(md, ["mgmt_ip", "management_ip", "management", "oob_ip"], default=""),
    }

    try:
        conf = load_config_by_id(target_node_id) if target_node_id else ""
        if conf:
            ci["config_excerpt"] = conf[:1500]
    except Exception:
        pass

    return ci


def _safe_chunk_text(chunk) -> str:
    """google.generativeai ã® stream chunk ã‹ã‚‰å®‰å…¨ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’å–ã‚Šå‡ºã™"""
    try:
        t = getattr(chunk, "text", "")
        if t:
            return t
    except Exception:
        pass

    try:
        cands = getattr(chunk, "candidates", None) or []
        if not cands:
            return ""
        content = getattr(cands[0], "content", None)
        parts = getattr(content, "parts", None) or []
        out = []
        for p in parts:
            tx = getattr(p, "text", "")
            if tx:
                out.append(tx)
        return "".join(out)
    except Exception:
        return ""


def run_diagnostic_simulation_no_llm(selected_scenario, target_node_obj):
    """LLMã‚’å‘¼ã°ãªã„ç–‘ä¼¼è¨ºæ–­ï¼ˆ503/ã‚³ã‚¹ãƒˆå¯¾ç­–ï¼‰"""
    device_id = getattr(target_node_obj, "id", "UNKNOWN") if target_node_obj else "UNKNOWN"
    ts = time.strftime("%Y-%m-%d %H:%M:%S")
    lines = [
        f"[PROBE] ts={ts}",
        f"[PROBE] scenario={selected_scenario}",
        f"[PROBE] target_device={device_id}",
        "",
    ]

    recovered_devices = st.session_state.get("recovered_devices") or {}
    recovered_map = st.session_state.get("recovered_scenario_map") or {}

    if recovered_devices.get(device_id) and recovered_map.get(device_id) == selected_scenario:
        if "FW" in selected_scenario:
            lines += [
                "show chassis cluster status",
                "Redundancy group 0: healthy",
                "control link: up",
                "fabric link: up",
            ]
        elif "WAN" in selected_scenario or "WANå…¨å›ç·šæ–­" in selected_scenario:
            lines += [
                "show ip interface brief",
                "GigabitEthernet0/0 up up",
                "show ip bgp summary",
                "Neighbor 203.0.113.2 Established",
                "ping 203.0.113.2 repeat 5",
                "Success rate is 100 percent (5/5)",
            ]
        elif "L2SW" in selected_scenario:
            lines += [
                "show environment",
                "Fan: OK",
                "Temperature: OK",
                "show interface status",
                "Uplink: up",
            ]
        else:
            lines += [
                "show system alarms",
                "No active alarms",
                "ping 8.8.8.8 repeat 5",
                "Success rate is 100 percent (5/5)",
            ]

        return {
            "status": "SUCCESS",
            "sanitized_log": "\n".join(lines),
            "verification_log": "N/A",
            "device_id": device_id,
        }

    if "WANå…¨å›ç·šæ–­" in selected_scenario or "[WAN]" in selected_scenario:
        lines += [
            "show ip interface brief",
            "GigabitEthernet0/0 down down",
            "show ip bgp summary",
            "Neighbor 203.0.113.2 Idle",
            "ping 203.0.113.2 repeat 5",
            "Success rate is 0 percent (0/5)",
        ]
    elif "FWç‰‡ç³»éšœå®³" in selected_scenario or "[FW]" in selected_scenario:
        lines += [
            "show chassis cluster status",
            "Redundancy group 0: degraded",
            "control link: down",
            "fabric link: up",
        ]
    elif "L2SW" in selected_scenario:
        lines += [
            "show environment",
            "Fan: FAIL",
            "Temperature: HIGH",
            "show interface status",
            "Uplink: flapping",
        ]
    else:
        lines += [
            "show system alarms",
            "No active alarms",
        ]

    return {
        "status": "SUCCESS",
        "sanitized_log": "\n".join(lines),
        "verification_log": "N/A",
        "device_id": device_id,
    }


def render_topology(alarms, root_cause_candidates):
    """ãƒˆãƒãƒ­ã‚¸ãƒ¼å›³ã®æç”»"""
    graph = graphviz.Digraph()
    graph.attr(rankdir='TB')
    graph.attr('node', shape='box', style='rounded,filled', fontname='Helvetica')

    alarm_map = {a.device_id: a for a in alarms}
    alarmed_ids = set(alarm_map.keys())
    root_cause_ids = {c['id'] for c in root_cause_candidates if c['prob'] > 0.6}
    node_status_map = {c['id']: c['type'] for c in root_cause_candidates}

    for node_id, node in TOPOLOGY.items():
        color = "#e8f5e9"
        penwidth = "1"
        fontcolor = "black"
        label = f"{node_id}\n({node.type})"

        red_type = node.metadata.get("redundancy_type")
        if red_type:
            label += f"\n[{red_type} Redundancy]"
        vendor = node.metadata.get("vendor")
        if vendor:
            label += f"\n[{vendor}]"

        status_type = node_status_map.get(node_id, "Normal")

        if "Hardware/Physical" in status_type or "Critical" in status_type or "Silent" in status_type:
            color = "#ffcdd2"
            penwidth = "3"
            label += "\n[ROOT CAUSE]"
        elif "Network/Unreachable" in status_type or "Network/Secondary" in status_type:
            color = "#cfd8dc"
            fontcolor = "#546e7a"
            label += "\n[Unreachable]"
        elif node_id in alarmed_ids:
            color = "#fff9c4"

        graph.node(node_id, label=label, fillcolor=color, color='black', penwidth=penwidth, fontcolor=fontcolor)

    for node_id, node in TOPOLOGY.items():
        if node.parent_id:
            graph.edge(node.parent_id, node_id)
            parent_node = TOPOLOGY.get(node.parent_id)
            if parent_node and parent_node.redundancy_group:
                partners = [n.id for n in TOPOLOGY.values()
                           if n.redundancy_group == parent_node.redundancy_group and n.id != parent_node.id]
                for partner_id in partners:
                    graph.edge(partner_id, node_id)
    return graph


# =====================================================
# UIæ§‹ç¯‰
# =====================================================
st.title("âš¡ Antigravity Autonomous Agent")

# ãƒ¬ãƒ¼ãƒˆåˆ¶é™çŠ¶æ³ã®è¡¨ç¤º
with st.sidebar:
    stats = rate_limiter.get_stats()
    st.caption(f"ğŸ“Š API: {stats['requests_last_minute']}/{stats['rpm_limit']} RPM | Cache: {stats['cache_size']}")

api_key = None
if "GOOGLE_API_KEY" in st.secrets:
    api_key = st.secrets["GOOGLE_API_KEY"]
else:
    api_key = os.environ.get("GOOGLE_API_KEY")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    st.header("âš¡ Scenario Controller")
    SCENARIO_MAP = {
        "åŸºæœ¬ãƒ»åºƒåŸŸéšœå®³": ["æ­£å¸¸ç¨¼åƒ", "1. WANå…¨å›ç·šæ–­", "2. FWç‰‡ç³»éšœå®³", "3. L2SWã‚µã‚¤ãƒ¬ãƒ³ãƒˆéšœå®³"],
        "WAN Router": ["4. [WAN] é›»æºéšœå®³ï¼šç‰‡ç³»", "5. [WAN] é›»æºéšœå®³ï¼šä¸¡ç³»", "6. [WAN] BGPãƒ«ãƒ¼ãƒˆãƒ•ãƒ©ãƒƒãƒ”ãƒ³ã‚°", "7. [WAN] FANæ•…éšœ", "8. [WAN] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯"],
        "Firewall (Juniper)": ["9. [FW] é›»æºéšœå®³ï¼šç‰‡ç³»", "10. [FW] é›»æºéšœå®³ï¼šä¸¡ç³»", "11. [FW] FANæ•…éšœ", "12. [FW] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯"],
        "L2 Switch": ["13. [L2SW] é›»æºéšœå®³ï¼šç‰‡ç³»", "14. [L2SW] é›»æºéšœå®³ï¼šä¸¡ç³»", "15. [L2SW] FANæ•…éšœ", "16. [L2SW] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯"],
        "è¤‡åˆãƒ»ãã®ä»–": ["17. [WAN] è¤‡åˆéšœå®³ï¼šé›»æºï¼†FAN", "18. [Complex] åŒæ™‚å¤šç™ºï¼šFW & AP", "99. [Live] Ciscoå®Ÿæ©Ÿè¨ºæ–­"]
    }
    selected_category = st.selectbox("å¯¾è±¡ã‚«ãƒ†ã‚´ãƒª:", list(SCENARIO_MAP.keys()))
    selected_scenario = st.radio("ç™ºç”Ÿã‚·ãƒŠãƒªã‚ª:", SCENARIO_MAP[selected_category])
    st.markdown("---")
    if api_key:
        st.success("API Connected")
    else:
        st.warning("API Key Missing")
        user_key = st.text_input("Google API Key", type="password")
        if user_key:
            api_key = user_key

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç† ---
if "current_scenario" not in st.session_state:
    st.session_state.current_scenario = "æ­£å¸¸ç¨¼åƒ"

for key in ["live_result", "messages", "chat_session", "trigger_analysis", "verification_result", 
            "generated_report", "verification_log", "last_report_cand_id", "logic_engine", 
            "recovered_devices", "recovered_scenario_map", "balloons_shown"]:
    if key not in st.session_state:
        if key == "messages":
            st.session_state[key] = []
        elif key in ["trigger_analysis", "balloons_shown"]:
            st.session_state[key] = False
        else:
            st.session_state[key] = None

if "recovered_devices" not in st.session_state:
    st.session_state.recovered_devices = {}
if "recovered_scenario_map" not in st.session_state:
    st.session_state.recovered_scenario_map = {}
if "global_cache" not in st.session_state:
    st.session_state.global_cache = {}

GLOBAL_CACHE = st.session_state.global_cache

# ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–
if not st.session_state.logic_engine:
    st.session_state.logic_engine = LogicalRCA(TOPOLOGY)

# ã‚·ãƒŠãƒªã‚ªåˆ‡ã‚Šæ›¿ãˆæ™‚ã®ãƒªã‚»ãƒƒãƒˆ
if st.session_state.current_scenario != selected_scenario:
    st.session_state.current_scenario = selected_scenario
    st.session_state.recovered_devices = {}
    st.session_state.recovered_scenario_map = {}
    st.session_state.messages = []
    st.session_state.chat_session = None
    st.session_state.live_result = None
    st.session_state.trigger_analysis = False
    st.session_state.verification_result = None
    st.session_state.generated_report = None
    st.session_state.verification_log = None
    st.session_state.last_report_cand_id = None
    st.session_state.balloons_shown = False
    if "remediation_plan" in st.session_state:
        del st.session_state.remediation_plan
    st.rerun()

# =====================================================
# ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯
# =====================================================
alarms = []
target_device_id = None
root_severity = "CRITICAL"
is_live_mode = False

# 1. ã‚¢ãƒ©ãƒ¼ãƒ ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯
if "Live" in selected_scenario:
    is_live_mode = True
elif "WANå…¨å›ç·šæ–­" in selected_scenario:
    target_device_id = find_target_node_id(TOPOLOGY, node_type="ROUTER")
    if target_device_id:
        alarms = simulate_cascade_failure(target_device_id, TOPOLOGY)
elif "FWç‰‡ç³»éšœå®³" in selected_scenario:
    target_device_id = find_target_node_id(TOPOLOGY, node_type="FIREWALL")
    if target_device_id:
        alarms = [Alarm(target_device_id, "Heartbeat Loss", "WARNING")]
        root_severity = "WARNING"
elif "L2SWã‚µã‚¤ãƒ¬ãƒ³ãƒˆéšœå®³" in selected_scenario:
    target_device_id = "L2_SW_01"
    if target_device_id not in TOPOLOGY:
        target_device_id = find_target_node_id(TOPOLOGY, keyword="L2_SW")
    if target_device_id and target_device_id in TOPOLOGY:
        child_nodes = [nid for nid, n in TOPOLOGY.items() if n.parent_id == target_device_id]
        alarms = [Alarm(child, "Connection Lost", "CRITICAL") for child in child_nodes]
    else:
        st.error("Error: L2 Switch definition not found")
elif "è¤‡åˆéšœå®³" in selected_scenario:
    target_device_id = find_target_node_id(TOPOLOGY, node_type="ROUTER")
    if target_device_id:
        alarms = [
            Alarm(target_device_id, "Power Supply 1 Failed", "CRITICAL"),
            Alarm(target_device_id, "Fan Fail", "WARNING")
        ]
elif "åŒæ™‚å¤šç™º" in selected_scenario:
    fw_node = find_target_node_id(TOPOLOGY, node_type="FIREWALL")
    ap_node = find_target_node_id(TOPOLOGY, node_type="ACCESS_POINT")
    alarms = []
    if fw_node:
        alarms.append(Alarm(fw_node, "Heartbeat Loss", "WARNING"))
    if ap_node:
        alarms.append(Alarm(ap_node, "Connection Lost", "CRITICAL"))
    target_device_id = fw_node
else:
    if "[WAN]" in selected_scenario:
        target_device_id = find_target_node_id(TOPOLOGY, node_type="ROUTER")
    elif "[FW]" in selected_scenario:
        target_device_id = find_target_node_id(TOPOLOGY, node_type="FIREWALL")
    elif "[L2SW]" in selected_scenario:
        target_device_id = find_target_node_id(TOPOLOGY, node_type="SWITCH", layer=4)

    if target_device_id:
        if "é›»æºéšœå®³ï¼šç‰‡ç³»" in selected_scenario:
            alarms = [Alarm(target_device_id, "Power Supply 1 Failed", "WARNING")]
            root_severity = "WARNING"
        elif "é›»æºéšœå®³ï¼šä¸¡ç³»" in selected_scenario:
            if "FW" in target_device_id:
                alarms = [Alarm(target_device_id, "Power Supply: Dual Loss (Device Down)", "CRITICAL")]
            else:
                alarms = simulate_cascade_failure(target_device_id, TOPOLOGY, "Power Supply: Dual Loss (Device Down)")
        elif "BGP" in selected_scenario:
            alarms = [Alarm(target_device_id, "BGP Flapping", "WARNING")]
            root_severity = "WARNING"
        elif "FAN" in selected_scenario:
            alarms = [Alarm(target_device_id, "Fan Fail", "WARNING")]
            root_severity = "WARNING"
        elif "ãƒ¡ãƒ¢ãƒª" in selected_scenario:
            alarms = [Alarm(target_device_id, "Memory High", "WARNING")]
            root_severity = "WARNING"

# 2. â˜…æ”¹å–„: ãƒãƒƒãƒå‡¦ç†å¯¾å¿œã®æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³
# ã‚¢ãƒ©ãƒ¼ãƒ ã‚’msg_mapå½¢å¼ã«å¤‰æ›
msg_map = {}
for alarm in alarms:
    if alarm.device_id not in msg_map:
        msg_map[alarm.device_id] = []
    msg_map[alarm.device_id].append(alarm.message)

# infer_root_cause (ãƒãƒƒãƒå‡¦ç†å¯¾å¿œ) ã‚’ä½¿ç”¨
analysis_results = st.session_state.logic_engine.infer_root_cause(msg_map)

# 3. ã‚³ãƒƒã‚¯ãƒ”ãƒƒãƒˆè¡¨ç¤º
selected_incident_candidate = None

st.markdown("### ğŸ›¡ï¸ AIOps ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ»ã‚³ãƒƒã‚¯ãƒ”ãƒƒãƒˆ")
col1, col2, col3 = st.columns(3)
with col1:
    st.metric("ğŸ“‰ ãƒã‚¤ã‚ºå‰Šæ¸›ç‡", "98.5%", "é«˜åŠ¹ç‡ç¨¼åƒä¸­")
with col2:
    st.metric("ğŸ“¨ å‡¦ç†ã‚¢ãƒ©ãƒ¼ãƒ æ•°", f"{len(alarms) * 15 if alarms else 0}ä»¶", "æŠ‘åˆ¶æ¸ˆ")
with col3:
    st.metric("ğŸš¨ è¦å¯¾å¿œã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆ", f"{len([c for c in analysis_results if c['prob'] > 0.6])}ä»¶", "å¯¾å‡¦ãŒå¿…è¦")
st.markdown("---")

df_data = []
for rank, cand in enumerate(analysis_results, 1):
    status = "âšª ç›£è¦–ä¸­"
    action = "ğŸ‘ï¸ é™è¦³"

    if cand['prob'] > 0.8:
        status = "ğŸ”´ å±é™º (æ ¹æœ¬åŸå› )"
        action = "ğŸš€ è‡ªå‹•ä¿®å¾©ãŒå¯èƒ½"
    elif cand['prob'] > 0.6:
        status = "ğŸŸ¡ è­¦å‘Š (è¢«ç–‘ç®‡æ‰€)"
        action = "ğŸ” è©³ç´°èª¿æŸ»ã‚’æ¨å¥¨"

    if "Network/Unreachable" in cand['type'] or "Network/Secondary" in cand['type']:
        status = "âš« å¿œç­”ãªã— (ä¸Šä½éšœå®³)"
        action = "â›” å¯¾å¿œä¸è¦ (ä¸Šä½å¾©æ—§å¾…ã¡)"

    candidate_text = f"ãƒ‡ãƒã‚¤ã‚¹: {cand['id']} / åŸå› : {cand['label']}"
    if cand.get('verification_log'):
        candidate_text += " [ğŸ” Active Probe: å¿œç­”ãªã—]"

    df_data.append({
        "é †ä½": rank,
        "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": status,
        "æ ¹æœ¬åŸå› å€™è£œ": candidate_text,
        "ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢": cand['prob'],
        "æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³": action,
        "ID": cand['id'],
        "Type": cand['type']
    })

df = pd.DataFrame(df_data)
st.info("ğŸ’¡ ãƒ’ãƒ³ãƒˆ: ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆã®è¡Œã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ã€å³å´ã«è©³ç´°åˆ†æã¨å¾©æ—§ãƒ—ãƒ©ãƒ³ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

event = st.dataframe(
    df,
    column_order=["é †ä½", "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", "æ ¹æœ¬åŸå› å€™è£œ", "ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢", "æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"],
    column_config={
        "ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢": st.column_config.ProgressColumn("ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ (0-1.0)", format="%.2f", min_value=0, max_value=1),
    },
    use_container_width=True,
    hide_index=True,
    selection_mode="single-row",
    on_select="rerun"
)

if len(event.selection.rows) > 0:
    idx = event.selection.rows[0]
    sel_row = df.iloc[idx]
    for res in analysis_results:
        if res['id'] == sel_row['ID'] and res['type'] == sel_row['Type']:
            selected_incident_candidate = res
            break
else:
    selected_incident_candidate = analysis_results[0] if analysis_results else None

# 4. ç”»é¢åˆ†å‰²
col_map, col_chat = st.columns([1.2, 1])

# === å·¦ã‚«ãƒ©ãƒ : ãƒˆãƒãƒ­ã‚¸ãƒ¼ã¨è¨ºæ–­ ===
with col_map:
    st.subheader("ğŸŒ Network Topology")

    current_root_node = None
    current_severity = "WARNING"

    if selected_incident_candidate and selected_incident_candidate["prob"] > 0.6:
        current_root_node = TOPOLOGY.get(selected_incident_candidate["id"])
        if "Hardware/Physical" in selected_incident_candidate["type"] or "Critical" in selected_incident_candidate["type"] or "Silent" in selected_incident_candidate["type"]:
            current_severity = "CRITICAL"
        else:
            current_severity = "WARNING"
    elif target_device_id:
        current_root_node = TOPOLOGY.get(target_device_id)
        current_severity = root_severity

    st.graphviz_chart(render_topology(alarms, analysis_results), use_container_width=True)

    st.markdown("---")
    st.subheader("ğŸ› ï¸ Auto-Diagnostics")

    if st.button("ğŸš€ è¨ºæ–­å®Ÿè¡Œ (Run Diagnostics)", type="primary"):
        if not api_key:
            st.error("API Key Required")
        else:
            with st.status("Agent Operating...", expanded=True) as status:
                st.write("ğŸ”Œ Connecting to device...")
                target_node_obj = TOPOLOGY.get(target_device_id) if target_device_id else None
                is_live = bool(st.session_state.get('api_connected')) and ('[Live]' in selected_scenario or 'Live' in selected_scenario)

                res = run_diagnostic_simulation(selected_scenario, target_node_obj, api_key) if is_live else run_diagnostic_simulation_no_llm(selected_scenario, target_node_obj)
                st.session_state.live_result = res

                if res["status"] == "SUCCESS":
                    st.write("âœ… Log Acquired & Sanitized.")
                    status.update(label="Diagnostics Complete!", state="complete", expanded=False)
                    log_content = res.get('sanitized_log', "")
                    verification = verify_log_content(log_content)
                    st.session_state.verification_result = verification
                    st.session_state.trigger_analysis = True
                elif res["status"] == "SKIPPED":
                    status.update(label="No Action Required", state="complete")
                else:
                    st.write("âŒ Connection Failed.")
                    status.update(label="Diagnostics Failed", state="error")
            st.rerun()

    if st.session_state.live_result:
        res = st.session_state.live_result
        if res["status"] == "SUCCESS":
            st.markdown("#### ğŸ“„ Diagnostic Results")
            with st.container(border=True):
                if selected_incident_candidate and selected_incident_candidate.get("verification_log"):
                    st.caption("ğŸ¤– Active Probe / Verification Log")
                else:
                    st.caption("ğŸ“ƒ Collected Log Data")
                st.code(res["sanitized_log"][:3000], language="text")

            if st.session_state.verification_result:
                st.markdown("#### ğŸ” Ground Truth Verification")
                report = format_verification_report(st.session_state.verification_result)
                st.markdown(report)

# === å³ã‚«ãƒ©ãƒ : è©³ç´°åˆ†æã¨å¾©æ—§ ===
with col_chat:
    if selected_incident_candidate:
        st.subheader(f"ğŸ“Š è©³ç´°åˆ†æ: {selected_incident_candidate['id']}")

        st.markdown(f"""
        **ãƒ‡ãƒã‚¤ã‚¹**: `{selected_incident_candidate['id']}`  
        **åŸå› **: `{selected_incident_candidate['label']}`  
        **ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢**: `{selected_incident_candidate['prob']:.2f}`  
        **åˆ†é¡**: `{selected_incident_candidate['type']}`  
        **ç†ç”±**: {selected_incident_candidate['reason']}
        """)

        if selected_incident_candidate.get('analyst_report'):
            with st.expander("ğŸ” AI Analyst Report", expanded=True):
                st.code(selected_incident_candidate['analyst_report'], language="text")

        if selected_incident_candidate.get('auto_investigation'):
            with st.expander("ğŸ“‹ æ¨å¥¨èª¿æŸ»é …ç›®", expanded=False):
                for item in selected_incident_candidate['auto_investigation']:
                    st.markdown(f"- {item}")

    # ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ï¼ˆãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒã‚¿ãƒ¼çµ±åˆï¼‰
    with st.expander("ğŸ’¬ Chat with AI Agent", expanded=False):
        _chat_target_id = ""
        try:
            if selected_incident_candidate:
                _chat_target_id = selected_incident_candidate.get("id", "") or ""
        except Exception:
            _chat_target_id = ""
        if not _chat_target_id:
            _chat_target_id = target_device_id if target_device_id else ""
        _chat_ci = _build_ci_context_for_chat(_chat_target_id) if _chat_target_id else {}
        if _chat_ci:
            _vendor = _chat_ci.get("vendor", "") or "Unknown"
            _os = _chat_ci.get("os", "") or "Unknown"
            _model = _chat_ci.get("model", "") or "Unknown"
            st.caption(f"å¯¾è±¡æ©Ÿå™¨: {_chat_target_id}   Vendor: {_vendor}   OS: {_os}   Model: {_model}")

        # ã‚¯ã‚¤ãƒƒã‚¯è³ªå•
        q1, q2, q3 = st.columns(3)
        if "chat_quick_text" not in st.session_state:
            st.session_state.chat_quick_text = ""

        with q1:
            if st.button("è¨­å®šãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—", use_container_width=True):
                st.session_state.chat_quick_text = "ã“ã®æ©Ÿå™¨ã§ã€ç¾åœ¨ã®è¨­å®šã‚’å®‰å…¨ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã™ã‚‹æ‰‹é †ã¨ã‚³ãƒãƒ³ãƒ‰ä¾‹ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"
        with q2:
            if st.button("ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯", use_container_width=True):
                st.session_state.chat_quick_text = "ã“ã®æ©Ÿå™¨ã§ã€å¤‰æ›´ã‚’ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯ã™ã‚‹ä»£è¡¨çš„ãªæ‰‹é †ï¼ˆå€™è£œï¼‰ã¨æ³¨æ„ç‚¹ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"
        with q3:
            if st.button("ç¢ºèªã‚³ãƒãƒ³ãƒ‰", use_container_width=True):
                st.session_state.chat_quick_text = "ä»Šå›ã®ç—‡çŠ¶ã‚’åˆ‡ã‚Šåˆ†ã‘ã‚‹ãŸã‚ã«ã€ã¾ãšå®Ÿè¡Œã™ã¹ãç¢ºèªã‚³ãƒãƒ³ãƒ‰ã‚’å„ªå…ˆåº¦é †ã«æ•™ãˆã¦ãã ã•ã„ã€‚"

        if st.session_state.chat_quick_text:
            st.info("ã‚¯ã‚¤ãƒƒã‚¯è³ªå•ï¼ˆã‚³ãƒ”ãƒ¼ã—ã¦è²¼ã‚Šä»˜ã‘ï¼‰")
            st.code(st.session_state.chat_quick_text)

        if st.session_state.chat_session is None and api_key:
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel("gemma-3-12b-it")
            st.session_state.chat_session = model.start_chat(history=[])

        tab1, tab2 = st.tabs(["ğŸ’¬ ä¼šè©±", "ğŸ“ å±¥æ­´"])

        with tab1:
            if st.session_state.messages:
                last_msg = st.session_state.messages[-1]
                if last_msg["role"] == "assistant":
                    st.info("ğŸ¤– æœ€æ–°ã®å›ç­”")
                    with st.container(height=300):
                        st.markdown(last_msg["content"])

            st.markdown("---")
            prompt = st.text_area(
                "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:",
                height=70,
                placeholder="Ctrl+Enter ã¾ãŸã¯ é€ä¿¡ãƒœã‚¿ãƒ³ã§é€ä¿¡",
                key="chat_textarea"
            )

            col1, col2, col3 = st.columns([3, 1, 1])
            with col2:
                send_button = st.button("é€ä¿¡", type="primary", use_container_width=True)
            with col3:
                if st.button("ã‚¯ãƒªã‚¢"):
                    st.session_state.messages = []
                    st.rerun()

            if send_button and prompt:
                st.session_state.messages.append({"role": "user", "content": prompt})

                if st.session_state.chat_session:
                    target_id = ""
                    try:
                        if selected_incident_candidate:
                            target_id = selected_incident_candidate.get("id", "") or ""
                    except Exception:
                        target_id = ""
                    if not target_id:
                        try:
                            target_id = target_device_id
                        except Exception:
                            target_id = ""
                    ci = _build_ci_context_for_chat(target_id) if target_id else {}
                    ci_prompt = f"""ã‚ãªãŸã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é‹ç”¨ï¼ˆNOC/SREï¼‰ã®å®Ÿå‹™è€…ã§ã™ã€‚
æ¬¡ã® CI æƒ…å ±ã¨ Config æŠœç²‹ã‚’å¿…ãšå‚ç…§ã—ã¦ã€å…·ä½“çš„ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚

ã€CI (JSON)ã€‘
{json.dumps(ci, ensure_ascii=False, indent=2)}

ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã€‘
{prompt}

å›ç­”ãƒ«ãƒ¼ãƒ«:
- CI/Config ã«åŸºã¥ãå…·ä½“æ‰‹é †ãƒ»ã‚³ãƒãƒ³ãƒ‰ä¾‹ã‚’æç¤ºã™ã‚‹
- è¿½åŠ ç¢ºèªãŒå¿…è¦ãªã‚‰ã€è³ªå•ã¯æœ€å°é™ã«çµã‚‹
- ä¸æ˜ãªå‰æã¯æ¨æ¸¬ã›ãšã€ŒCIã«ç„¡ã„ã®ã§ç¢ºèªãŒå¿…è¦ã€ã¨æ˜è¨˜ã™ã‚‹
"""

                    with st.spinner("AI ãŒå›ç­”ã‚’ç”Ÿæˆä¸­..."):
                        try:
                            response = generate_content_with_retry(
                                st.session_state.chat_session.model,
                                ci_prompt,
                                stream=False
                            )
                            if response:
                                full_response = response.text if hasattr(response, "text") else str(response)
                                if not full_response.strip():
                                    full_response = "AIå¿œç­”ãŒç©ºã§ã—ãŸã€‚"
                                st.session_state.messages.append({"role": "assistant", "content": full_response})
                            else:
                                st.error("AIã‹ã‚‰ã®å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                        except Exception as e:
                            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                    st.rerun()

        with tab2:
            if st.session_state.messages:
                history_container = st.container(height=400)
                with history_container:
                    for i, msg in enumerate(st.session_state.messages):
                        icon = "ğŸ¤–" if msg["role"] == "assistant" else "ğŸ‘¤"
                        with st.container(border=True):
                            st.markdown(f"{icon} **{msg['role'].upper()}** (ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ {i+1})")
                            st.markdown(msg["content"])
            else:
                st.info("ä¼šè©±å±¥æ­´ã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")

# ãƒ™ã‚¤ã‚ºæ›´æ–°ãƒˆãƒªã‚¬ãƒ¼
if st.session_state.trigger_analysis and st.session_state.live_result:
    if st.session_state.verification_result:
        pass
    st.session_state.trigger_analysis = False
